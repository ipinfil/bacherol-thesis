# -*- coding: utf-8 -*-
"""BakalarskaPracaKlasifikacia.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1CISvF-HrCJXx_fIK1tqmBFTrtn96fb33

Import Tensorflow.
"""

import tensorflow as tf
from tensorflow import keras
from keras import layers
import os
import numpy as np
import argparse
import json

def build_model(num_classes):
    model = tf.keras.applications.ResNet50(
        include_top=False,
        weights="imagenet",
        input_tensor=None,
        input_shape=None,
        pooling=None,
        classes=131
    )

    # Freeze the pretrained weights
    model.trainable = False

    # Rebuild top
    x = layers.GlobalAveragePooling2D(name="avg_pool")(model.output)
    x = layers.BatchNormalization()(x)

    top_dropout_rate = 0.2
    x = layers.Dropout(top_dropout_rate, name="top_dropout")(x)
    outputs = layers.Dense(num_classes, activation="softmax", name="pred")(x)

    # Compile
    model = tf.keras.Model(model.input, outputs, name="ResNet50")
    # checkpoint at end of epoch
    # callbacks = [
    #     keras.callbacks.ModelCheckpoint("save_at_{epoch}.h5"),
    # ]
    model.compile(
        optimizer=keras.optimizers.Adam(1e-3),
        loss="categorical_crossentropy",
        metrics=["accuracy"],
    )
    return model

"""Control via arguments."""
parser = argparse.ArgumentParser("Train fruit and vegetable recoginition neural network based on ResNet50.")
parser.add_argument("--ds-path", type=str)
parser.add_argument("--predict-only", action="store_true")
parser.add_argument("--predict-path", type=str)
parser.add_argument("--model-path", type=str)
args = parser.parse_args()

image_size = (100, 100)

if not args.predict_only:
    """Create training and validation sets."""
    batch_size = 32
    dataset_root_dir = args.ds_path

    datagen = tf.keras.preprocessing.image.ImageDataGenerator(
        featurewise_center=True,
        featurewise_std_normalization=True,
        preprocessing_function=tf.keras.applications.resnet50.preprocess_input,
        validation_split=0.2
        )

    train_ds = datagen.flow_from_directory(
        directory=dataset_root_dir,
        target_size=image_size,
        color_mode="rgb",
        batch_size=32,
        class_mode="categorical",
        shuffle=True,
        seed=42,
        subset="training"
    )

    val_ds = datagen.flow_from_directory(
        directory=dataset_root_dir,
        target_size=image_size,
        color_mode="rgb",
        batch_size=32,
        class_mode="categorical",
        shuffle=True,
        seed=42,
        subset="validation"
    )

    """Define model."""
    model = build_model(131)

    """Train model."""
    epochs = 1
    history = model.fit(
        train_ds, epochs=epochs, validation_data=val_ds
    )

    if args.model_path:
        model.save(args.model_path)

if args.predict_path and args.model_path:
    img = keras.preprocessing.image.load_img(
        args.predict_path, target_size=image_size
    )
    img_array = keras.preprocessing.image.img_to_array(img)
    img_array = tf.expand_dims(img_array, 0)  # Create batch axis
    img_array = keras.applications.resnet50.preprocess_input(img_array)

    try:
        model
    except NameError:
        model = keras.models.load_model(args.model_path)

    predictions = model.predict(img_array)

    try:
        class_names = os.listdir(dataset_root_dir) # Reads all the folders in which images are present
        class_names = sorted(class_names) # Sorting them
    except NameError:
        with open("classes.json", "r") as f:
            class_names = list(json.load(f).keys())

    predictions_decoded = {class_names[i] : value * 100 for i, value in sorted(enumerate(predictions[0]), key=lambda val: val[1], reverse=True)}
    float_formatter = "{:.2f}".format

    for class_name in predictions_decoded:
        if predictions_decoded[class_name] < 0.01:
            continue
        print(class_name + " - " + f"{predictions_decoded[class_name]:.2f}" + "%")